\section{Background}

\subsection{Hidden Markov Model}
A hidden Markov model assumes that the system follows a Markov process. For this paper, we will assume a finite number of states and observations. The probability of transitioning from state $i$ to state $j$ only depends on the current state, and we define transition matrix $A$ such that element $a_{ij}$ is the probability  of transitioning from $i$ to $j$. In an HMM, we cannot observe states, but we can observe outputs generated by the states. Given $N$ states and $M$ observations, we capture this with a $N \times M$ emission matrix $B$, where $b_{ij}$ is the probability of observation $j$ given the state is $i$. Finally, we define a $N$ length vector as $\pi$ as the prior, where $\pi_i$ is the probability of initial state being $i$. 

We can thus capture all the information about an HMM with $\theta = (A, B, \pi)$. In an HMM, we are given a sequence of $T$ observations, and we will use a series of forward and backwards propagations to estimate the parameters $\theta = (A, B, \pi)$.

\subsection{Baum-Welch}
Let $(X_1, X_2, \ldots, X_N)$ denote the $N$ states and $\bold{O} = \{O_1, O_2, \ldots, O_T\}$ the $T$ observed outputs. The Baum-Welch uses expectation-maximization to find the maximum likelihood estimate.

We set $\theta  =  (A, B, \pi)$ randomly. For the forward procedure, we define $\alpha_i(t) = P(O_1 = o_t, \ldots, O_t = o_t | \theta)$. That is, the probability of observing the first $t$ outputs given a set of parameters. We can then iteratively find:
$$\alpha_i(t+1) =  b_{jo_1}\sum_{i=1}^{N} \alpha_i(t)a_{ij}$$
For backwards procedure, we define $\beta_i(t) = P(O_{t+1} = o_{t+1}, \ldots, O_T = o_T | \theta)$, the probability of observing the last $T - t$ outputs given a set of parameters. We can find $\beta$ iteratively by:
$$\beta_i(t) = \sum_{i=1}^N \beta_j(t+1)a_{ij}b_j(o_{t+1})$$.

Now define $\gamma_i(t)$ to be the probability of being in state $i$ given $\bold{O}$ and parameter $\theta$. We can update $\gamma_i(t)$ as:

$$\gamma_i(t) = P(X_t = i | \bold{O}, \theta) = \frac{\alpha_i(t) \beta_i(t)}{\sum_{j=1}^N \alpha_j(t) \beta_j(t)}$$

We define $\xi_{ij}(t)$ to be the probability of being in state $i$ at time $t$ and state $j$ at time $t+1$ given $\bold{O}$ and parameter $\theta$. 
$$
\begin{aligned}
\xi_{ij}(t) &= P(X_t = i, X_{t+1} = j | \bold{O}, \theta)  \\
&=\frac{\alpha_i(t) a_{ij} \beta_j(t+1)b_{jo_{t+1}}}{\sum_{k=1}^N \alpha_k(t) \beta_k(t)}
\end{aligned}
$$ 

We can now update our parameters. We update $\pi$ by:
$$\pi_i^* = \gamma_i(t)$$
We update $A$ by:
$$a^*_{ij} = \frac{\sum_{t=1}^{T-1}\xi_{ij}(t)}{\sum_{t=1}^{T-1}\gamma_i(t)}$$
We update $B$ by:
$$b^*_{iv_k} = \frac{\sum_{t=1}^{T}1_{o_t = v_k} \gamma_i(t)}{\sum_{t=1}^T \gamma_i(t)}$$ 
where $1_{o_t = v_k}$ is $1$ if $o_t = v_k$ and $0$ otherwise. 

These steps are repeated until the parameters converge. 